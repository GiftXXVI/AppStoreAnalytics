{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:09<00:00,  1.34s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [12:25<00:00, 106.57s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pygments import highlight\n",
    "from pygments.lexers import JsonLexer\n",
    "from pygments.formatters import TerminalFormatter\n",
    "\n",
    "from google_play_scraper import Sort, reviews, app\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "app_packages = [\n",
    "    'com.google.android.apps.meetings',\n",
    "    'com.instagram.android',\n",
    "    'com.microsoft.teams',\n",
    "    'com.netflix.mediaclient',\n",
    "    'com.zhiliaoapp.musically',\n",
    "    'com.whatsapp',\n",
    "    'us.zoom.videomeetings'\n",
    "]\n",
    "\n",
    "app_infos = []\n",
    "\n",
    "for ap in tqdm(app_packages):\n",
    "  info = app(ap, lang='en', country='us')\n",
    "  del info['comments']\n",
    "  app_infos.append(info)    \n",
    "\n",
    "app_infos_df = pd.DataFrame(app_infos)\n",
    "app_infos_df.to_csv('apps.csv', index=None, header=True)\n",
    "\n",
    "app_reviews = []\n",
    "\n",
    "for ap in tqdm(app_packages):\n",
    "  for score in list(range(1, 6)):\n",
    "    for sort_order in [Sort.NEWEST]:\n",
    "      rvs, _ = reviews(\n",
    "        ap,\n",
    "        lang='en',\n",
    "        country='us',\n",
    "        sort=sort_order,\n",
    "        count= 2000,\n",
    "        filter_score_with=score\n",
    "      )\n",
    "      for r in rvs:\n",
    "        r['sortOrder'] = 'most_relevant' if sort_order == Sort.MOST_RELEVANT else 'newest'\n",
    "        r['appId'] = ap\n",
    "      app_reviews.extend(rvs)\n",
    "\n",
    "app_reviews_df = pd.DataFrame(app_reviews)\n",
    "app_reviews_df.to_csv('reviews.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.059*\"great\" + 0.055*\"meet\" + 0.037*\"screen\" + 0.037*\"phone\" + 0.022*\"option\" + 0.021*\"record\" + 0.018*\"nice\" + 0.018*\"easy\" + 0.016*\"application\" + 0.015*\"work\"\n",
      "Topic: 1 \n",
      "Words: 0.040*\"nice\" + 0.027*\"video\" + 0.026*\"update\" + 0.025*\"good\" + 0.024*\"meet\" + 0.020*\"data\" + 0.019*\"need\" + 0.018*\"gmail\" + 0.016*\"class\" + 0.014*\"screen\"\n",
      "Topic: 2 \n",
      "Words: 0.071*\"meet\" + 0.065*\"class\" + 0.031*\"online\" + 0.031*\"time\" + 0.028*\"join\" + 0.024*\"good\" + 0.018*\"help\" + 0.014*\"show\" + 0.013*\"update\" + 0.013*\"google\"\n",
      "Topic: 3 \n",
      "Words: 0.145*\"good\" + 0.037*\"class\" + 0.037*\"online\" + 0.034*\"video\" + 0.033*\"nice\" + 0.029*\"meet\" + 0.024*\"quality\" + 0.024*\"time\" + 0.018*\"google\" + 0.015*\"star\"\n",
      "Topic: 4 \n",
      "Words: 0.057*\"meet\" + 0.033*\"thank\" + 0.029*\"work\" + 0.028*\"screen\" + 0.024*\"voice\" + 0.019*\"google\" + 0.018*\"video\" + 0.016*\"join\" + 0.016*\"problem\" + 0.016*\"good\"\n",
      "Topic: 5 \n",
      "Words: 0.464*\"good\" + 0.031*\"work\" + 0.025*\"meet\" + 0.018*\"update\" + 0.013*\"class\" + 0.011*\"join\" + 0.010*\"mode\" + 0.007*\"screen\" + 0.007*\"properly\" + 0.007*\"open\"\n",
      "Topic: 6 \n",
      "Words: 0.070*\"video\" + 0.066*\"best\" + 0.037*\"meet\" + 0.032*\"audio\" + 0.028*\"quality\" + 0.024*\"good\" + 0.015*\"issue\" + 0.015*\"google\" + 0.014*\"worst\" + 0.013*\"chat\"\n",
      "Topic: 7 \n",
      "Words: 0.291*\"nice\" + 0.056*\"class\" + 0.052*\"online\" + 0.040*\"useful\" + 0.037*\"love\" + 0.032*\"meet\" + 0.025*\"update\" + 0.020*\"google\" + 0.017*\"students\" + 0.011*\"good\"\n",
      "Topic: 8 \n",
      "Words: 0.090*\"super\" + 0.048*\"like\" + 0.048*\"better\" + 0.033*\"option\" + 0.027*\"awesome\" + 0.022*\"good\" + 0.021*\"chat\" + 0.018*\"zoom\" + 0.017*\"rate\" + 0.013*\"version\"\n",
      "Topic: 9 \n",
      "Words: 0.121*\"meet\" + 0.045*\"problem\" + 0.041*\"google\" + 0.035*\"join\" + 0.022*\"good\" + 0.019*\"like\" + 0.016*\"update\" + 0.013*\"star\" + 0.012*\"excellent\" + 0.011*\"class\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"reviews_google_meet.csv\")\n",
    "data_text = data[['content']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "\n",
    "def lemmatize_only(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_only(token))\n",
    "    return result\n",
    "\n",
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "\n",
    "processed_docs = documents['content'].map(preprocess)\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=5000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n",
    "\n",
    "print('\\nBag of Words Model:\\n')\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    \n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "\n",
    "print('\\nTF-IDF Model:\\n')\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
